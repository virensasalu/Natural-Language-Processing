{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zDBF1PXEDfhw"
   },
   "source": [
    "# Pre-trained Language Models: SubTask C \n",
    "## [8 Marks]\n",
    "\n",
    "In this assignment, you will work on the [ComVE](https://competitions.codalab.org/competitions/21080) shared task that was part of SemEval-2020. The task aims to evaluate whether a system can distinguish if a natural language statement makes sense to humans or not and provide a reason. **ConVE** includes three subtasks that require models to acquire and apply commonsense knowledge. In this notebook you will focus on **SubTask C**:\n",
    "\n",
    "- Given a statement that does not make sense, generate the reason why this statement does not make sense. For each nonsensical statement, three valid reasons are given as reference:\n",
    "\n",
    "     *Statement*: He put an elephant into the fridge.  \n",
    "     *Reason A*: An elephant is much bigger than a fridge.  \n",
    "     *Reason B*: A fridge is much smaller than an elephant.  \n",
    "     *Reason C*: Most of the fridges aren't large enough to contain an elephant.\n",
    "\n",
    "     This subtask can be approached as a Sequence-to-Sequence problem where the input is the nonsensical statement and the output is a valid reason.\n",
    "\n",
    "You will fine-tune a Pre-trained Language Model with [Transformers](https://huggingface.co/docs/transformers/index) library that provides a set of tools for fine-tunning and deploying a wide variety of Pre-trained Language Models. The [Hugging Face Hub](https://huggingface.co/models) allows you to explore all the models supported by **Transformers** and even share your own models with the community. In this assignment, you will work with [BART](https://huggingface.co/docs/transformers/model_doc/bart), a pre-trained Sequence-to-Sequence model.\n",
    "\n",
    "Fine-tuning a Pre-trained Language Model usually requires a great amount of time and computational resources. Your personal computer will not be enough. In order to complete the assignment, you can work with a reduced version of the dataset and the base version of **BART**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "X6DavXXpDfhy"
   },
   "outputs": [],
   "source": [
    "shrink_dataset = True\n",
    "base_model = True\n",
    "colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "fI5Uu0_gDfhz"
   },
   "source": [
    "Although the value of these variables do not affect the tests that will evaluate your code, the output examples distributed throughout this notebook are based on a `shrink_dataset` and a `base_model` variables set as `True`, and a `colab` variable set as `False`.\n",
    "\n",
    "If you want to perform a full training of the model to obtain its real performance, you can use a cloud service like [Google Colab](https://colab.research.google.com/). **Colab** is a **Jupyter** notebook environment that supports both GPU and TPU instances, allowing training large scale Deep Learning models. Set the `shrink_dataset` and a `base_model` variables to `False`, the `colab` variable to `True`, and follow the instructions provided to you to run the notebook in **Colab**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gEqfRl12Dfhz"
   },
   "outputs": [],
   "source": [
    "if colab:\n",
    "    ! pip install transformers datasets evaluate\n",
    "    import os\n",
    "    if not os.path.exists(\"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_data_all.csv\"):\n",
    "        ! git clone https://github.com/wangcunxiang/SemEval2020-Task4-Commonsense-Validation-and-Explanation.git SemEval2020-Task4-Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "U1c3v4XVDfhz"
   },
   "source": [
    "You will use the following objects and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Nef4cdirDfhz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, \n",
    "                          Seq2SeqTrainingArguments, Seq2SeqTrainer, \n",
    "                          DataCollatorForSeq2Seq, enable_full_determinism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rjm8g6k8Dfhz"
   },
   "source": [
    "When working with Neural Networks, there are a large number of random operations such as initializing the weights of the network, shuffling the data for training, or choosing samples. This causes that different training runs of the same model can lead to different results. To ensure reproducibility, i.e. obtaining the same results in the different runs, the random number generator must be initialized with a fixed value known as seed. In Transformers, this can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9GC6UlXcDfh0"
   },
   "outputs": [],
   "source": [
    "enable_full_determinism(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "J8U_rnboDfh0"
   },
   "source": [
    "> **Note!** With models as complex as Neural Networks, reproducibility is susceptible to factors such as software versions or the hardware on which the models are run. Even with seed initialization, there may be slight differences in the results.\n",
    "\n",
    "Working with Neural Networks also involves defining a number of hyperparameters that set the configuration of the model. Finding the appropriate hyperparameter values requires training the model with different combinations and testing them on the development set. This hyperparameter tuning is a costly process that needs multiple rounds of experimentation. However, for this assignments, you will use the following values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "8eBiASC4Dfh0"
   },
   "outputs": [],
   "source": [
    "epochs = 3  # Number of epochs to train the model\n",
    "train_batch_size = 8  # Number of examples used per gradient update\n",
    "learning_rate = 1e-5  # The learning rate for the optimizer\n",
    "max_length = 25  # Maximum lenght of the input sequence\n",
    "output_dir = \"modelC\"  # The output directory where the model will be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eAd8K6wXDfh0"
   },
   "source": [
    "> **Note!** The notebook for this assignment provides very little guidance. You are expected to refer to the [documentation](https://huggingface.co/docs) for details on how to solve the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kGbzR7H8Dfh0"
   },
   "source": [
    "## Loading the Pre-trained Model - [1 Mark]\n",
    "\n",
    "The first step you must perform in this assignment is to load the model and its corresponding tokenizer using the classes imported above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Yk7tOsLaDfh0"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name):   #[1 Mark]\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(tokenizer)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "lEVPC3rlDfh0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartTokenizerFast(name_or_path='facebook/bart-base', vocab_size=50265, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/bart-base\" if base_model else \"facebook/bart-large\"\n",
    "model, tokenizer = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-q7CcBksDfh1"
   },
   "source": [
    "## Data Pre-processing - [2 Marks]\n",
    "\n",
    "The **ComVE** dataset consists of 10000 nonsensical statements for the train set, 997 statements for development and 1000 for test. Each nonsensical statements comes with with three reference valid reasons. You must load the three sets into three `DataFrames`. For the training and development splits, the `DataFrame` should contain three columns: the `id` of the nonsensical statement, a `FalseSent` column with the nonsensical statement and a `reason` column with the reference reasons. For the test set, the `DataFrame` should contain five columns: the `id` of the nonsensical statement, a `FalseSent` column with the nonsensical statement and three columns (`reason1`, `reason2` and `reason3`) containing each of the reference reasons.\n",
    "\n",
    "Train DataFrame:\n",
    "\n",
    "|       |   id | FalseSent                                         | reason                                                                         |\n",
    "|------:|-----:|:--------------------------------------------------|:-------------------------------------------------------------------------------|\n",
    "|   769 |  769 | Computers is an ingredient used in preparing food | Computers are not used for food and they are not edible                        |\n",
    "| 10769 |  769 | Computers is an ingredient used in preparing food | Computer is not something that can be used in preparing food.                  |\n",
    "| 20769 |  769 | Computers is an ingredient used in preparing food | You cannot eat a computer                                                      |\n",
    "|   888 |  888 | he did hear music in his cooling glass            | cooling glass can not play the song, it's not a electronic thing to play music |\n",
    "| 10888 |  888 | he did hear music in his cooling glass            | Glass does not produce music.                                                  |\n",
    "| 20888 |  888 | he did hear music in his cooling glass            | Any sound that might be made by a cooling glass is not music.                  |\n",
    "\n",
    "Test DataFrame:\n",
    "\n",
    "|     |   id | FalseSent                                      | reason1                                                  | reason2                                                | reason3                                                            |\n",
    "|----:|-----:|:-----------------------------------------------|:---------------------------------------------------------|:-------------------------------------------------------|:-------------------------------------------------------------------|\n",
    "|  76 | 1280 | Beer that is drunk by humans is white          | Beer is made of barley and it is a yellow drink          | A beer that is drunk by humans is not white.           | Beer is brown                                                      |\n",
    "| 101 |  860 | eating trash food every day makes you stronger | eating trash food every day makes your body fat and weak | eating trash food every day is bad for your health     | Trash food could be contaminated                                   |\n",
    "| 136 |  777 | he put some cooking oil in his wine            | cooking oil will destroy the taste of the wine           | Cooking oil does not go in wine                        | Cooking oil does not taste nice and therefore would ruin the wine. |\n",
    "| 174 |  570 | Lobsters live in the mountains                 | Lobsters needs water to live                             | Lobsters live in the sea.                              | Lobsters live in the sea, not the mountains                        |\n",
    "| 210 | 1929 | the clock shows animals                        | the clock is used to show the time to people             | Clocks are required to tell the time, not show animals | a clock shows the time not animals                                 |\n",
    "| 235 | 1619 | she put the giraffe in the freezer             | A giraffe is much bigger than the freezer                | There is no way a giraffe is fitting in the freezer.   | A giraffe is too big to be put in a freezer.                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(data_csv, answers_csv, is_test=False):   # 1 Mark\n",
    "#     data = pd.read_csv(data_csv).dropna()\n",
    "#     answers = pd.read_csv(answers_csv, header= None).rename(columns={0: \"id\",  1: \"reason1\", 2: \"reason2\", 3: \"reason3\"})\n",
    "#     if is_test:\n",
    "       \n",
    "#         return pd.merge(data, answers, on=\"id\")\n",
    "#     else:\n",
    "       \n",
    "#         return pd.merge(data, answers.melt(id_vars=[\"id\"], value_vars=[\"reason1\", \"reason2\", \"reason3\"], value_name=\"reason\").drop(columns=[\"variable\"]), on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def load_data(data_csv, answers_csv, is_test=False):\n",
    "#     # Read data from data_csv and drop rows with missing values\n",
    "#     data = pd.read_csv(data_csv).dropna()\n",
    "    \n",
    "#     # Read answers from answers_csv and assign column names\n",
    "#     answers = pd.read_csv(answers_csv, header=None).rename(columns={0: \"id\", 1: \"reason1\", 2: \"reason2\", 3: \"reason3\"})\n",
    "    \n",
    "#     if is_test:\n",
    "#         # Merge data with answers directly based on the \"id\" column\n",
    "#         return pd.merge(data, answers, on=\"id\")\n",
    "#     else:\n",
    "#         # Reshape answers DataFrame for training and development data\n",
    "#         reshaped_answers = answers.melt(id_vars=[\"id\"], value_vars=[\"reason1\", \"reason2\", \"reason3\"], value_name=\"reason\").drop(columns=[\"variable\"])\n",
    "#         # Merge reshaped answers with data based on the \"id\" column\n",
    "#         return pd.merge(data, reshaped_answers, on=\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(data_csv, answers_csv, is_test=False):\n",
    "    # Read data from data_csv and drop rows with missing values\n",
    "    data = pd.read_csv(data_csv).dropna()\n",
    "    \n",
    "    # Read answers from answers_csv\n",
    "    answers = pd.read_csv(answers_csv, header=None)\n",
    "    \n",
    "    if is_test:\n",
    "        # For test set, directly merge data with answers using \"id\" column\n",
    "        answers.columns = [\"id\", \"reason1\", \"reason2\", \"reason3\"]\n",
    "        return pd.merge(data, answers, on=\"id\")\n",
    "    else:\n",
    "        # For training and development sets, reshape answers DataFrame\n",
    "        answers.columns = [\"id\", \"reason1\", \"reason2\", \"reason3\"]\n",
    "        reshaped_answers = pd.concat([answers[\"id\"], answers.iloc[:, 1:].stack().reset_index(level=1, drop=True).rename(\"reason\")], axis=1)\n",
    "        return pd.merge(data, reshaped_answers, on=\"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data(data_csv, answers_csv, is_test=False):\n",
    "\n",
    "#     data = pd.read_csv(data_csv)\n",
    "\n",
    "#     answers = pd.read_csv(answers_csv, header=None )\n",
    "#     # Merge data and answers based on the ID column\n",
    "#     merged_df = pd.merge(data, answers, on=\"id\")\n",
    "#     if is_test:\n",
    "#         # For test set, return DataFrame with five columns\n",
    "#         return merged_df \n",
    "#     else:\n",
    "#         melted_df = pd.melt(merged_df, id_vars=['id', 'FalseSent'],\n",
    "#                             value_vars = ['reason1','reason2', 'reason3'],\n",
    "#                            var_name='reason_number', value_name='reason')\n",
    "#         # Sort by 'id' and reason number' to have the reasons in order\n",
    "#         melted_df.sort_values(by=['id', 'reason_number'], inplace=True)\n",
    "#         # Reset index for clarity\n",
    "#         melted_df.reset_index(drop=True, inplace=True)\n",
    "#         melted_df.drop (columns=['reason_number'], inplace=True)\n",
    "#         return melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tE231iQzDfh1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>769</td>\n",
       "      <td>Computers is an ingredient used in preparing food</td>\n",
       "      <td>Computers are not used for food and they are not edible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>769</td>\n",
       "      <td>Computers is an ingredient used in preparing food</td>\n",
       "      <td>Computer is not something that can be used in preparing food.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2309</th>\n",
       "      <td>769</td>\n",
       "      <td>Computers is an ingredient used in preparing food</td>\n",
       "      <td>You cannot eat a computer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2664</th>\n",
       "      <td>888</td>\n",
       "      <td>he did hear music in his cooling glass</td>\n",
       "      <td>cooling glass can not play the song, it's not a electronic thing to play music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2665</th>\n",
       "      <td>888</td>\n",
       "      <td>he did hear music in his cooling glass</td>\n",
       "      <td>Glass does not produce music.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>888</td>\n",
       "      <td>he did hear music in his cooling glass</td>\n",
       "      <td>Any sound that might be made by a cooling glass is not music.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                          FalseSent  \\\n",
       "2307  769  Computers is an ingredient used in preparing food   \n",
       "2308  769  Computers is an ingredient used in preparing food   \n",
       "2309  769  Computers is an ingredient used in preparing food   \n",
       "2664  888             he did hear music in his cooling glass   \n",
       "2665  888             he did hear music in his cooling glass   \n",
       "2666  888             he did hear music in his cooling glass   \n",
       "\n",
       "                                                                              reason  \n",
       "2307                         Computers are not used for food and they are not edible  \n",
       "2308                   Computer is not something that can be used in preparing food.  \n",
       "2309                                                       You cannot eat a computer  \n",
       "2664  cooling glass can not play the song, it's not a electronic thing to play music  \n",
       "2665                                                   Glass does not produce music.  \n",
       "2666                   Any sound that might be made by a cooling glass is not music.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>FalseSent</th>\n",
       "      <th>reason1</th>\n",
       "      <th>reason2</th>\n",
       "      <th>reason3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1280</td>\n",
       "      <td>Beer that is drunk by humans is white</td>\n",
       "      <td>Beer is made of barley and it is a yellow drink</td>\n",
       "      <td>A beer that is drunk by humans is not white.</td>\n",
       "      <td>Beer is brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>860</td>\n",
       "      <td>eating trash food every day makes you stronger</td>\n",
       "      <td>eating trash food every day makes your body fat and weak</td>\n",
       "      <td>eating trash food every day is bad for your health</td>\n",
       "      <td>Trash food could be contaminated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>777</td>\n",
       "      <td>he put some cooking oil in his wine</td>\n",
       "      <td>cooking oil will destroy the taste of the wine</td>\n",
       "      <td>Cooking oil does not go in wine</td>\n",
       "      <td>Cooking oil does not taste nice and therefore would ruin the wine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>570</td>\n",
       "      <td>Lobsters live in the mountains</td>\n",
       "      <td>Lobsters needs water to live</td>\n",
       "      <td>Lobsters live in the sea.</td>\n",
       "      <td>Lobsters live in the sea, not the mountains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1929</td>\n",
       "      <td>the clock shows animals</td>\n",
       "      <td>the clock is used to show the time to people</td>\n",
       "      <td>Clocks are required to tell the time, not show animals</td>\n",
       "      <td>a clock shows the time not animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1619</td>\n",
       "      <td>she put the giraffe in the freezer</td>\n",
       "      <td>A giraffe is much bigger than the freezer</td>\n",
       "      <td>There is no way a giraffe is fitting in the freezer.</td>\n",
       "      <td>A giraffe is too big to be put in a freezer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                       FalseSent  \\\n",
       "76   1280           Beer that is drunk by humans is white   \n",
       "101   860  eating trash food every day makes you stronger   \n",
       "136   777             he put some cooking oil in his wine   \n",
       "174   570                  Lobsters live in the mountains   \n",
       "210  1929                         the clock shows animals   \n",
       "235  1619              she put the giraffe in the freezer   \n",
       "\n",
       "                                                      reason1  \\\n",
       "76            Beer is made of barley and it is a yellow drink   \n",
       "101  eating trash food every day makes your body fat and weak   \n",
       "136            cooking oil will destroy the taste of the wine   \n",
       "174                              Lobsters needs water to live   \n",
       "210              the clock is used to show the time to people   \n",
       "235                 A giraffe is much bigger than the freezer   \n",
       "\n",
       "                                                    reason2  \\\n",
       "76             A beer that is drunk by humans is not white.   \n",
       "101      eating trash food every day is bad for your health   \n",
       "136                         Cooking oil does not go in wine   \n",
       "174                               Lobsters live in the sea.   \n",
       "210  Clocks are required to tell the time, not show animals   \n",
       "235    There is no way a giraffe is fitting in the freezer.   \n",
       "\n",
       "                                                                reason3  \n",
       "76                                                        Beer is brown  \n",
       "101                                    Trash food could be contaminated  \n",
       "136  Cooking oil does not taste nice and therefore would ruin the wine.  \n",
       "174                         Lobsters live in the sea, not the mountains  \n",
       "210                                  a clock shows the time not animals  \n",
       "235                        A giraffe is too big to be put in a freezer.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data_csv = \"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_data_all.csv\"\n",
    "train_answers_csv = \"SemEval2020-Task4-Data/ALL data/Training  Data/subtaskC_answers_all.csv\"\n",
    "train_data = load_data(train_data_csv, train_answers_csv)\n",
    "dev_data_csv = \"SemEval2020-Task4-Data/ALL data/Dev Data/subtaskC_dev_data.csv\"\n",
    "dev_answers_csv = \"SemEval2020-Task4-Data/ALL data/Dev Data/subtaskC_gold_answers.csv\"\n",
    "dev_data = load_data(dev_data_csv, dev_answers_csv)\n",
    "test_data_csv = \"SemEval2020-Task4-Data/ALL data/Test Data/subtaskC_test_data.csv\"\n",
    "test_answers_csv = \"SemEval2020-Task4-Data/ALL data/Test Data/subtaskC_gold_answers.csv\"\n",
    "test_data = load_data(test_data_csv, test_answers_csv, True)\n",
    "if shrink_dataset:\n",
    "    idxs = train_data[\"id\"].sample(frac=1, random_state=42).unique()[:30]\n",
    "    train_data = train_data[train_data.id.isin(idxs)]\n",
    "    idxs = dev_data[\"id\"].sample(frac=1, random_state=42).unique()[:30]\n",
    "    dev_data = dev_data[dev_data.id.isin(idxs)]\n",
    "    idxs = test_data[\"id\"].sample(frac=1, random_state=42).unique()[:30]\n",
    "    test_data = test_data[test_data.id.isin(idxs)]\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "print(\"Train DataFrame:\")\n",
    "display(train_data[:6])\n",
    "print(\"Test DataFrame:\")\n",
    "display(test_data[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DJU-01EtDfh1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 769,\n",
       " 'FalseSent': 'Computers is an ingredient used in preparing food',\n",
       " 'reason': 'Computers are not used for food and they are not edible',\n",
       " '__index_level_0__': 2307}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset example:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 1280,\n",
       " 'FalseSent': 'Beer that is drunk by humans is white',\n",
       " 'reason1': 'Beer is made of barley and it is a yellow drink',\n",
       " 'reason2': 'A beer that is drunk by humans is not white.',\n",
       " 'reason3': 'Beer is brown',\n",
       " '__index_level_0__': 76}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "dev_dataset = Dataset.from_pandas(dev_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "print(\"Train Dataset example:\")\n",
    "display(train_dataset[0])\n",
    "print(\"Test Dataset example:\")\n",
    "display(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HsEcHmGiDfh1"
   },
   "source": [
    "The `Datasets` should be pre-processed following two different approaches. For the test `Dataset`, you must run the tokenizer on the `FalseSent` column and store the result in the `input_ids` and `attention_mask` fields. For the train and development `Datasets` you must also run the tokenizer on the `reason` column and store the resulting `input_ids` in the `labels` field. In all cases, the tokenizer must pad and truncate the sequences to the `max_length` value.\n",
    "\n",
    "><pre>\n",
    ">Train formated Dataset example:\n",
    ">\n",
    ">{'id': 769, 'FalseSent': 'Computers is an ingredient used in preparing food', 'reason': 'Computers are not used for food and they are not edible', '__index_level_0__': 769, 'input_ids': [0, 14721, 43990, 16, 41, 16181, 341, 11, 4568, 689, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0, 14721, 43990, 32, 45, 341, 13, 689, 8, 51, 32, 45, 27532, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
    ">\n",
    ">Test formated Dataset example:\n",
    ">\n",
    ">{'id': 1280, 'FalseSent': 'Beer that is drunk by humans is white', 'reason1': 'Beer is made of barley and it is a yellow drink', 'reason2': 'A beer that is drunk by humans is not white.', 'reason3': 'Beer is brown', '__index_level_0__': 76, 'input_ids': [0, 45562, 14, 16, 10789, 30, 5868, 16, 1104, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
    "></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(examples, tokenizer, max_length, is_test=False):   # [1 Mark]\n",
    "    encoded_data = tokenizer(\n",
    "        examples[\"FalseSent\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    if not is_test:\n",
    "        if \"reason\" in examples:\n",
    "            encoded_data[\"labels\"] = tokenizer(\n",
    "                examples[\"reason\"],\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_tensors=\"pt\"\n",
    "            )[\"input_ids\"]\n",
    "        else:\n",
    "            raise KeyError(\"Column 'reason' not found in the dataset.\")\n",
    "    \n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TYDVjG1SDfh1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11aeeda810b4447e8454bdeb7d2779e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94932a9394ed4b77b9d1087c84d310c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2661727179864524a5da6982c5f8d681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train formated Dataset example:\n",
      "\n",
      "{'id': 769, 'FalseSent': 'Computers is an ingredient used in preparing food', 'reason': 'Computers are not used for food and they are not edible', '__index_level_0__': 2307, 'input_ids': [0, 14721, 43990, 16, 41, 16181, 341, 11, 4568, 689, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0, 14721, 43990, 32, 45, 341, 13, 689, 8, 51, 32, 45, 27532, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "Test formated Dataset example:\n",
      "\n",
      "{'id': 1280, 'FalseSent': 'Beer that is drunk by humans is white', 'reason1': 'Beer is made of barley and it is a yellow drink', 'reason2': 'A beer that is drunk by humans is not white.', 'reason3': 'Beer is brown', '__index_level_0__': 76, 'input_ids': [0, 45562, 14, 16, 10789, 30, 5868, 16, 1104, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda x: preprocess_data(x, tokenizer, max_length), batched=True)\n",
    "dev_dataset = dev_dataset.map(lambda x: preprocess_data(x, tokenizer, max_length), batched=True)\n",
    "test_dataset = test_dataset.map(lambda x: preprocess_data(x, tokenizer, max_length, True), batched=True)\n",
    "print(\"Train formated Dataset example:\\n\")\n",
    "print(train_dataset[0])\n",
    "print(\"\\nTest formated Dataset example:\\n\")\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "SE65PJbXDfh2"
   },
   "source": [
    "## Fine-tuning - [5 Marks]\n",
    "\n",
    "In general, when using a `Trainer` to make predictions, it returns the logits for each class in the task. However, the `Seq2SeqTrainingArguments` class provides an option that allows the `Trainer` to generate sequences of tokens in the prediction. The `create_training_arguments` function must create the `Seq2SeqTrainingArguments` with that option and the hyperparamters passed as arguments. During the training, the model must be evaluated on the development set after every epoch. `TrainingArguments` should include this strategy.\n",
    "\n",
    "> **Important!** By default, `Trainer` saves a checkpoint of the model every 500 training steps. For this assignment, avoid this behavior by setting `save_strategy=\"no\"` when creating the `TrainingArguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "NYcGf9LtDfh2"
   },
   "outputs": [],
   "source": [
    "def create_training_arguments(epochs, train_batch_size, learning_rate, output_dir):   # [1 Mark]\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=train_batch_size,\n",
    "        per_device_eval_batch_size=train_batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        evaluation_strategy=\"epoch\",  \n",
    "        save_strategy=\"no\",  \n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    \n",
    "    enable_full_determinism(training_args.seed)  \n",
    "    \n",
    "    return training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OMIWd-JsDfh2"
   },
   "outputs": [],
   "source": [
    "train_args = create_training_arguments(epochs, train_batch_size, learning_rate, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "LlaJ4yJxDfh2"
   },
   "source": [
    "Next, you can create a `Trainer` object initializing the appropriate data collator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "b3Zqw2vpDfh2"
   },
   "outputs": [],
   "source": [
    "def create_trainer(model, train_args, train_dataset, dev_dataset, tokenizer):   # [1 Mark]\n",
    "    datacollator = DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        data_collator=datacollator,\n",
    "    )\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3E2txek_Dfh2"
   },
   "outputs": [],
   "source": [
    "trainer = create_trainer(model, train_args, train_dataset, dev_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wtQpnSvdDfh2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 02:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.951546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.297704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.122463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=8.837547302246094, metrics={'train_runtime': 161.3134, 'train_samples_per_second': 1.674, 'train_steps_per_second': 0.223, 'total_flos': 4019258880000.0, 'train_loss': 8.837547302246094, 'epoch': 3.0})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e7Dq4Z3QDfh2"
   },
   "source": [
    "If you have set the `Seq2SeqTrainingArguments` properly, you could now use the `Trainer` to predict sequences of tokens. Take into account that `Trainer` will return the indexes of the tokens, so the sequence must be decoded to obtain the text strings. The `tokenizer` provides functionality to do this. The result of this process can be stored in the `prediction` column of the test `DataFrame`:\n",
    "\n",
    "|     |   id | FalseSent                                      | reason1                                                  | reason2                                                | reason3                                                            | prediction                                     |\n",
    "|----:|-----:|:-----------------------------------------------|:---------------------------------------------------------|:-------------------------------------------------------|:-------------------------------------------------------------------|:-----------------------------------------------|\n",
    "|  76 | 1280 | Beer that is drunk by humans is white          | Beer is made of barley and it is a yellow drink          | A beer that is drunk by humans is not white.           | Beer is brown                                                      | Beer that is drunk by humans is white                             |\n",
    "| 101 |  860 | eating trash food every day makes you stronger | eating trash food every day makes your body fat and weak | eating trash food every day is bad for your health     | Trash food could be contaminated                                   | eating trash food every day makes you stronger |\n",
    "| 136 |  777 | he put some cooking oil in his wine            | cooking oil will destroy the taste of the wine           | Cooking oil does not go in wine                        | Cooking oil does not taste nice and therefore would ruin the wine. | he put some cooking oil in his wine            |\n",
    "| 174 |  570 | Lobsters live in the mountains                 | Lobsters needs water to live                             | Lobsters live in the sea.                              | Lobsters live in the sea, not the mountains                        | Lobsters live in mountains                 |\n",
    "| 210 | 1929 | the clock shows animals                        | the clock is used to show the time to people             | Clocks are required to tell the time, not show animals | a clock shows the time not animals                                 | the clock shows animals                        |\n",
    "| 235 | 1619 | she put the giraffe in the freezer             | A giraffe is much bigger than the freezer                | There is no way a giraffe is fitting in the freezer.   | A giraffe is too big to be put in a freezer.                       | she put the giraffe in the freezer             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "8igEq42FDfh2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def make_predictions(trainer, test_dataset, tokenizer):\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    logits = predictions.predictions\n",
    "\n",
    "    # Convert logits to PyTorch tensors\n",
    "    logits_tensors = [torch.tensor(logits_part) for logits_part in logits]\n",
    "\n",
    "    # Transpose each tensor to match expected shape\n",
    "    logits_transposed = [torch.transpose(logits_part, 1, 2) for logits_part in logits_tensors]\n",
    "\n",
    "    # Apply softmax activation to each tensor\n",
    "    probabilities = [torch.softmax(logits_part, dim=-1) for logits_part in logits_transposed]\n",
    "\n",
    "    # Convert probabilities to numpy arrays\n",
    "    probabilities_np = [prob.numpy() for prob in probabilities]\n",
    "\n",
    "    return probabilities_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zaptZPfJDfh2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m make_predictions(trainer, test_dataset, tokenizer)\n\u001b[0;32m----> 2\u001b[0m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions\n\u001b[1;32m      3\u001b[0m test_data\n",
      "File \u001b[0;32m~/Documents/coding/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3612\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3611\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/coding/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:3784\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3775\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3777\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3782\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3783\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3784\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3786\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3787\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3788\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3789\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3790\u001b[0m     ):\n\u001b[1;32m   3791\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3792\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/Documents/coding/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:4509\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4509\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/coding/anaconda3/lib/python3.10/site-packages/pandas/core/common.py:531\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 531\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    535\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    536\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (2) does not match length of index (30)"
     ]
    }
   ],
   "source": [
    "predictions = make_predictions(trainer, test_dataset, tokenizer)\n",
    "test_data[\"prediction\"] = predictions\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2gAv_hl0Dfh3"
   },
   "source": [
    "The **Subtasks B** of **ComVE** is evaluated using the *bleu* metric. In this assignment, you will also evaluate using *rouge*. With `shrink_dataset` and `base_model` set to `True`, the expected scores are *0.216* and *0.446* for *bleu* and *rouge* respectively. With a full training run, i.e. with `shrink_dataset` and `base_model` set to `False`, the scores should be around *0.228* and *0.461*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yDJ79cPoDfh3"
   },
   "outputs": [],
   "source": [
    "def evaluate_prediction(test_data, metric):\n",
    "    if metric == \"bleu\":\n",
    "    \n",
    "        references = test_data[\"reason\"].tolist()\n",
    "        candidates = test_data[\"prediction\"].tolist()\n",
    "\n",
    "        bleu_score = corpus_bleu([[ref.split()] for ref in references], [cand.split() for cand in candidates])\n",
    "        return bleu_score\n",
    "\n",
    "    elif metric == \"rouge\":\n",
    "      \n",
    "        references = test_data[\"reason\"].tolist()\n",
    "        candidates = test_data[\"prediction\"].tolist()\n",
    "\n",
    "       \n",
    "        rouge = Rouge()\n",
    "\n",
    "     \n",
    "        rouge_scores = rouge.get_scores(candidates, references, avg=True)\n",
    "        rouge_score = rouge_scores[\"rouge-1\"][\"f\"]  # You can choose other metrics like \"rouge-2\" or \"rouge-l\" as well\n",
    "        return rouge_score\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported metric. Supported metrics are 'bleu' and 'rouge'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MztCvvWyDfh3"
   },
   "outputs": [],
   "source": [
    " evaluate_prediction(test_data, \"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7aIBv1uODfh3"
   },
   "outputs": [],
   "source": [
    "evaluate_prediction(test_data, \"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "s0D-JhuDDfh3"
   },
   "source": [
    "The scores for the partial training and the full training are so similar that it would appear that the full training does not provide any benefit in this task. However, it should be noted that the test sets in the two cases are different. More importantly, these results are indicative of the limitations of metrics such as *bleu* and *rouge* for evaluating text generation. Take, for example, the following case from the test set:\n",
    "\n",
    "\n",
    "| FalseSent                 | reason1                                        | reason2                          | reason3                         |\n",
    "|:--------------------------|:-----------------------------------------------|:---------------------------------|:--------------------------------|\n",
    "| Beer that is drunk by humans is white | Beer is made of barley and it is a yellow drink | A beer that is drunk by humans is not white. | Beer is brown |\n",
    "\n",
    "The predictions obtained by the partial and full trainings and their corresponding scores are the following:\n",
    "\n",
    "| full training    | prediction                 | bleu     | rouge    |\n",
    "|:-----------------|:---------------------------|---------:|---------:|\n",
    "| no               | Beer that is drunk by humans is white  | 0.731    | 0.889    |\n",
    "| yes              | White beer is not suitable for human consumption. | 0.000    | 0.364    |\n",
    "\n",
    "The text generated by the full training is a better explanation than the reason generated by the partial training, which is a mere repetition of the nonsensical statement. However, the latter obtains much better scores than the former. Metrics such as *bleu* and *rouge* do not always replace accurately the human judgement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
